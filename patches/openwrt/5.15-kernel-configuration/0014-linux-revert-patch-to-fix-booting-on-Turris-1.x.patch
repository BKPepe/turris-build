From 7869db7998609010e15484de67f0b78af44af839 Mon Sep 17 00:00:00 2001
From: Josef Schlehofer <pepe.schlehofer@gmail.com>
Date: Thu, 21 Jul 2022 13:14:58 +0200
Subject: [PATCH] linux: revert patch to fix booting on Turris 1.x

---
 ...se-lwarx-ldarx-directly-instead-of-P.patch | 144 ++++++++++++++++++
 1 file changed, 144 insertions(+)
 create mode 100644 target/linux/mpc85xx/patches-5.15/0001-Revert-powerpc-Use-lwarx-ldarx-directly-instead-of-P.patch

diff --git a/target/linux/mpc85xx/patches-5.15/0001-Revert-powerpc-Use-lwarx-ldarx-directly-instead-of-P.patch b/target/linux/mpc85xx/patches-5.15/0001-Revert-powerpc-Use-lwarx-ldarx-directly-instead-of-P.patch
new file mode 100644
index 0000000000..1ed5b4f9e2
--- /dev/null
+++ b/target/linux/mpc85xx/patches-5.15/0001-Revert-powerpc-Use-lwarx-ldarx-directly-instead-of-P.patch
@@ -0,0 +1,144 @@
+From d234ca3c5b1bc94508cec752eb3d429f717f30f2 Mon Sep 17 00:00:00 2001
+From: Josef Schlehofer <pepe.schlehofer@gmail.com>
+Date: Thu, 21 Jul 2022 13:13:33 +0200
+Subject: [PATCH] Revert "powerpc: Use lwarx/ldarx directly instead of
+ PPC_LWARX/LDARX macros"
+
+This reverts commit 9401f4e46cf6965e23738f70e149172344a01eef.
+---
+ arch/powerpc/include/asm/asm-compat.h      | 4 ++--
+ arch/powerpc/include/asm/atomic.h          | 4 ++--
+ arch/powerpc/include/asm/bitops.h          | 8 ++++----
+ arch/powerpc/include/asm/ppc-opcode.h      | 2 ++
+ arch/powerpc/include/asm/simple_spinlock.h | 6 +++---
+ 5 files changed, 13 insertions(+), 11 deletions(-)
+
+diff --git a/arch/powerpc/include/asm/asm-compat.h b/arch/powerpc/include/asm/asm-compat.h
+index 2b736d9fbb1b..19b70c5b5f18 100644
+--- a/arch/powerpc/include/asm/asm-compat.h
++++ b/arch/powerpc/include/asm/asm-compat.h
+@@ -17,7 +17,7 @@
+ #define PPC_LONG	stringify_in_c(.8byte)
+ #define PPC_LONG_ALIGN	stringify_in_c(.balign 8)
+ #define PPC_TLNEI	stringify_in_c(tdnei)
+-#define PPC_LLARX	stringify_in_c(ldarx)
++#define PPC_LLARX(t, a, b, eh)	PPC_LDARX(t, a, b, eh)
+ #define PPC_STLCX	stringify_in_c(stdcx.)
+ #define PPC_CNTLZL	stringify_in_c(cntlzd)
+ #define PPC_MTOCRF(FXM, RS) MTOCRF((FXM), RS)
+@@ -50,7 +50,7 @@
+ #define PPC_LONG	stringify_in_c(.long)
+ #define PPC_LONG_ALIGN	stringify_in_c(.balign 4)
+ #define PPC_TLNEI	stringify_in_c(twnei)
+-#define PPC_LLARX	stringify_in_c(lwarx)
++#define PPC_LLARX(t, a, b, eh)	PPC_LWARX(t, a, b, eh)
+ #define PPC_STLCX	stringify_in_c(stwcx.)
+ #define PPC_CNTLZL	stringify_in_c(cntlzw)
+ #define PPC_MTOCRF	stringify_in_c(mtcrf)
+diff --git a/arch/powerpc/include/asm/atomic.h b/arch/powerpc/include/asm/atomic.h
+index 6a53ef178bfd..a1732a79e92a 100644
+--- a/arch/powerpc/include/asm/atomic.h
++++ b/arch/powerpc/include/asm/atomic.h
+@@ -207,7 +207,7 @@ arch_atomic_try_cmpxchg_lock(atomic_t *v, int *old, int new)
+ 	int r, o = *old;
+ 
+ 	__asm__ __volatile__ (
+-"1:	lwarx	%0,0,%2,%5	# atomic_try_cmpxchg_acquire		\n"
++"1:\t"	PPC_LWARX(%0,0,%2,1) "	# atomic_try_cmpxchg_acquire	\n"
+ "	cmpw	0,%0,%3							\n"
+ "	bne-	2f							\n"
+ "	stwcx.	%4,0,%2							\n"
+@@ -215,7 +215,7 @@ arch_atomic_try_cmpxchg_lock(atomic_t *v, int *old, int new)
+ "\t"	PPC_ACQUIRE_BARRIER "						\n"
+ "2:									\n"
+ 	: "=&r" (r), "+m" (v->counter)
+-	: "r" (&v->counter), "r" (o), "r" (new), "i" (IS_ENABLED(CONFIG_PPC64) ? 1 : 0)
++	: "r" (&v->counter), "r" (o), "r" (new)
+ 	: "cr0", "memory");
+ 
+ 	if (unlikely(r != o))
+diff --git a/arch/powerpc/include/asm/bitops.h b/arch/powerpc/include/asm/bitops.h
+index 11847b6a244e..299ab33505a6 100644
+--- a/arch/powerpc/include/asm/bitops.h
++++ b/arch/powerpc/include/asm/bitops.h
+@@ -70,7 +70,7 @@ static inline void fn(unsigned long mask,	\
+ 	unsigned long *p = (unsigned long *)_p;	\
+ 	__asm__ __volatile__ (			\
+ 	prefix					\
+-"1:"	PPC_LLARX "%0,0,%3,0\n"			\
++"1:"	PPC_LLARX(%0,0,%3,0) "\n"		\
+ 	stringify_in_c(op) "%0,%0,%2\n"		\
+ 	PPC_STLCX "%0,0,%3\n"			\
+ 	"bne- 1b\n"				\
+@@ -115,13 +115,13 @@ static inline unsigned long fn(			\
+ 	unsigned long *p = (unsigned long *)_p;		\
+ 	__asm__ __volatile__ (				\
+ 	prefix						\
+-"1:"	PPC_LLARX "%0,0,%3,%4\n"			\
++"1:"	PPC_LLARX(%0,0,%3,eh) "\n"			\
+ 	stringify_in_c(op) "%1,%0,%2\n"			\
+ 	PPC_STLCX "%1,0,%3\n"				\
+ 	"bne- 1b\n"					\
+ 	postfix						\
+ 	: "=&r" (old), "=&r" (t)			\
+-	: "r" (mask), "r" (p), "i" (IS_ENABLED(CONFIG_PPC64) ? eh : 0)	\
++	: "r" (mask), "r" (p)				\
+ 	: "cc", "memory");				\
+ 	return (old & mask);				\
+ }
+@@ -170,7 +170,7 @@ clear_bit_unlock_return_word(int nr, volatile unsigned long *addr)
+ 
+ 	__asm__ __volatile__ (
+ 	PPC_RELEASE_BARRIER
+-"1:"	PPC_LLARX "%0,0,%3,0\n"
++"1:"	PPC_LLARX(%0,0,%3,0) "\n"
+ 	"andc %1,%0,%2\n"
+ 	PPC_STLCX "%1,0,%3\n"
+ 	"bne- 1b\n"
+diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
+index 536d997539bb..c475c12de561 100644
+--- a/arch/powerpc/include/asm/ppc-opcode.h
++++ b/arch/powerpc/include/asm/ppc-opcode.h
+@@ -579,6 +579,8 @@
+ #define	PPC_DIVDEU(t, a, b)	stringify_in_c(.long PPC_RAW_DIVDEU(t, a, b))
+ #define PPC_DSSALL		stringify_in_c(.long PPC_INST_DSSALL)
+ #define PPC_LQARX(t, a, b, eh)	stringify_in_c(.long PPC_RAW_LQARX(t, a, b, eh))
++#define PPC_LDARX(t, a, b, eh)	stringify_in_c(.long PPC_RAW_LDARX(t, a, b, eh))
++#define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_RAW_LWARX(t, a, b, eh))
+ #define PPC_STQCX(t, a, b)	stringify_in_c(.long PPC_RAW_STQCX(t, a, b))
+ #define PPC_MADDHD(t, a, b, c)	stringify_in_c(.long PPC_RAW_MADDHD(t, a, b, c))
+ #define PPC_MADDHDU(t, a, b, c)	stringify_in_c(.long PPC_RAW_MADDHDU(t, a, b, c))
+diff --git a/arch/powerpc/include/asm/simple_spinlock.h b/arch/powerpc/include/asm/simple_spinlock.h
+index 8985791a2ba5..552f325412cc 100644
+--- a/arch/powerpc/include/asm/simple_spinlock.h
++++ b/arch/powerpc/include/asm/simple_spinlock.h
+@@ -51,7 +51,7 @@ static inline unsigned long __arch_spin_trylock(arch_spinlock_t *lock)
+ 
+ 	token = LOCK_TOKEN;
+ 	__asm__ __volatile__(
+-"1:	lwarx		%0,0,%2,1\n\
++"1:	" PPC_LWARX(%0,0,%2,1) "\n\
+ 	cmpwi		0,%0,0\n\
+ 	bne-		2f\n\
+ 	stwcx.		%1,0,%2\n\
+@@ -179,7 +179,7 @@ static inline long __arch_read_trylock(arch_rwlock_t *rw)
+ 	long tmp;
+ 
+ 	__asm__ __volatile__(
+-"1:	lwarx		%0,0,%1,1\n"
++"1:	" PPC_LWARX(%0,0,%1,1) "\n"
+ 	__DO_SIGN_EXTEND
+ "	addic.		%0,%0,1\n\
+ 	ble-		2f\n"
+@@ -203,7 +203,7 @@ static inline long __arch_write_trylock(arch_rwlock_t *rw)
+ 
+ 	token = WRLOCK_TOKEN;
+ 	__asm__ __volatile__(
+-"1:	lwarx		%0,0,%2,1\n\
++"1:	" PPC_LWARX(%0,0,%2,1) "\n\
+ 	cmpwi		0,%0,0\n\
+ 	bne-		2f\n"
+ "	stwcx.		%1,0,%2\n\
+-- 
+2.34.1
+
-- 
2.34.1

